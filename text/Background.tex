\section{Background}
\label{sec:background}
Since we seek to optimize SGEMM at assembly-level, this section introduces some CUDA binary utilities used in our work. Besides, we highlight tunable factors that determine SGEMM's performance on GPU architecture.

\subsection{CUDA Binary Utilities}
\label{sec:cuda}

A CUDA binary file, also called {\em cubin}, is an ELF-formatted file generated by CUDA compiler ({\tt nvcc}). It can be either embedded into a host executable file or generated separately by using the "{\em -cubin}" option of {\tt nvcc}. To help developers understand {\em cubin} files, CUDA toolkit introduces binary tools and documents on ISAs from GT200 to Maxwell architecture~\cite{gtx980}. These binary tools only provide very limited functionalities for users. For instance, both {\tt cuobjdump} and {\tt nvdiasm} disassemble {\em cubin} files to {\em sass} files, which are readable assembly codes for examining possible performance issues in GPU programs. For each instruction in the executable code sections, the tools list its address in hexadecimal, mnemonics in string, and encoded number in hexadecimal. For example, an {\tt IADD} instruction might be printed as follows: \\\\
$/*0048*/~~~~IADD~~R0,~~R2,~~R0;~~/* 0x4800000000201c03 */$\\\\
Unfortunately, these tools do not enable us to modify the assembly codes directly for tuning performance. What we can do is to refine CUDA C codes after examining the read-only assembly codes iteratively. Therefore, an assembler is required to manipulate assembly codes. Although NVIDIA does not release its internal assembler and instruction encoding format, the disassembled code and the released pseudo assembly references~\cite{ptx2015isa}, provide us clues to crack instruction format (in Section~\ref{sec:assembler}).


\subsection{Performance Factors of SGEMM}
\label{sec:sgemm}
It's well-known that the primary factors of SGEMM performance are the blocking parameters for exploiting data reuse through memory hierarchy. On GPUs, we should consider both shared memory blocking and register blocking. For the purpose of completeness, we describe a blocking algorithm which is similar to that in other literature~\cite{magma,nervana_sgemm_wiki,lai,tan}.

Algorithm~\ref{gemm} shows the skeleton of SGEMM blocking algorithm. Task partition is based on the result matrix $C$. Each thread block with $tx*ty$ threads is responsible to compute a $bm*bn$ submatrix in $C$, where $bm, bn$ are the number of rows and columns of the submatrix, respectively. We need read a $bm*bk$ from A and a $bk*bn$ sub-matrix from B for each thread block, where $bk$ is unroll factor. In this way, $A$, $B$ and $C$ are divided into $M*K$, $K*N$ and $M*N$ grids of $bm*bk$, $bk*bn$ and $bm*bn$ blocks, where $M=\Bigl\lfloor \frac{m+bm-1}{bm} \Bigr\rfloor$, $K=\Bigl\lfloor \frac{k+bk-1}{bk} \Bigr\rfloor$, $N=\Bigl\lfloor \frac{n+bn-1}{bn} \Bigr\rfloor$.

\begin{algorithm}
  \caption{SGEMM blocking algorithm. {\em smA} and {\em smB} are shared memory variables. {\em rA}, {\em rB} and {\em accum} are register variables. $rx$ and $ry$ are register blocking sizes}
  \label{gemm}
  \begin{algorithmic}[1]
	\LineComment {The size of a thread block: $tx*ty$}
	\LineComment {Registers: accum[$rx*ry$], rA[$2*rx$], rB[$2*ry$]}
	\State $smA[bm][bk] \gets$ a $bm * bk$ block of $A$
	\State $smB[bk][bn] \gets$ a $bk * bn$ block of $B$
	\Do
      \For {{$i \gets 1, bk$}}
      %\Comment {\color {mygray} {Unrolling for loop}}
      \Comment {{Unrolling for loop}}
      \State {\color {black} {$rA[0...rx]\gets$ a column of $smA$}}
	\State $rB[0...ry]\gets$ a row of $smB$
	\State $accum[0...rx][0...ry]\gets accum[0...rx][0...ry]+rA[0...rx]*rB[0...ry]$
	\EndFor
	\State $smA[bk][bm]\gets$ a $bm*bk$ block of $A$
	\State $smB[bk][bn]\gets$ a $bk*bn$ block of $B$
	\State \textbf{sync}
	\doWhile {pointer in $B$ is out of range}
	\State \textbf{merge} $accum[0...rx][0...ry]$ with a $bm*bn$ block of $C$.
  \end{algorithmic}
\end{algorithm}

The volume of float point computations inside the while loop of Algorithm~\ref{gemm} is $2\times rx\times ry \times bk$ in operations, and Table~\ref{tab:reg} estimates data movement volume through registers, shared memory, and global memory for each threads inside while loop.
These parameters demonstrate that SGEMM performance is affected by the hierarchical memory blocking and unrolling factors in the inner loops.
The tuning of these factors is conducted in two folds--memory bandwidth and latency. In fact, with the estimations in Table~\ref{tab:reg}, it is relatively easy to tune proper parameters to eliminate the bound of memory bandwidth~\cite{magma}~\cite{tan}. The difficulty lies in latency, which is closely related to specific microarchitectures such as instruction sequence, instruction type and so on. However, the microarchitectural optimizations depend on the availability of an assembler and deep understanding of microarchitectural features. %TODO the second last sentence

\begin{table}[!t]
\caption{Data movement volume of each thread inside while loop}
\centering
\scalebox{1.0} {
\begin{tabular}{|c|c|}
\hline
    Data path& Volume(in words)\\
\hline
    global$\Rightarrow$regitster ({\tt LDG})& $\frac{rx*\times ry \times bk}{bm} + \frac{rx\times ry \times bk}{bn}$ \\
\hline
register$\Rightarrow$shared ({\tt STS})& $\frac{rx*\times ry \times bk}{bm} + \frac{rx\times ry \times bk}{bn}$ \\
\hline
shared$\Rightarrow$register ({\tt LDS})& $rx\times bk + ry\times bk$\\
\hline
%    arithemtic({\tt FFMA})& $rx\times ry \times bk$\\
%\hline
\end{tabular}
}
\label{tab:reg}
\end{table}
