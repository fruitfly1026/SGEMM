\section{Evaluation}
\label{sec:experiment}


In this section, we compare the optimized SGEMM performance in Gflop/s with NVIDIA cuBLAS. 
Our SGEMM achieves $17\%\sim 25\%$ performance
improvement, which confirms the usefulness of the microarchitectural optimization on GPU. 
We present 
a quantitative analysis on the effect of each optimization strategy and an estimation of the upper bound performance using a roofline model.

The experiments are conducted on NVIDIA K20m GPU with its hardware configuration summarized in 
Table~\ref{table:k20}. We compare with cuBLAS from CUDA $7.0$. In our experiments, we choose square matrix for $A$, $B$
and $C$, and  the matrix sizes vary in $768\times768$, $1536\times1536$, $3072\times3072$, $6144\times6144$, $12288\times12288$.
%\jled{C size? What about A and B?}

\begin{table}[htbp]
\caption{The specification of NVIDIA Tesla K20m GPU.}
\centering
\scalebox{0.8} {
\begin{tabular}{|c|c|}
\hline
% Metric& Value\\
Configuration& Value\\
\hline
SPs/SM &192\\
\hline
SMs&13\\
\hline
Cores &2496\\
\hline
Frequency&705MHz\\
\hline
Memory Bus Width&320bit \\
\hline
Memory frequency&2600MHz\\
\hline
Bandwidth&208.0GB/s\\
\hline
Peak GFlop/s in SP&3520GFlop/s\\
\hline
Warp scheduler per SM&4\\
\hline
Dispatch unit/SM&8\\
\hline
Max Registers/thread&256 \\
\hline
    32-bit registers/SM&65536 \\ %\jled{Use actual number}\\
\hline
LD/ST unit&32 \\
\hline
shared memory size&48KB\\
\hline
L1 cache size&16KB or 48KB\\
\hline
L2 cache size&1536KB\\
\hline
\end{tabular}
}
\label{table:k20}
\end{table}


\subsection{Overall Performance}
Figure~\ref{fig:sgemm_tn} reports the performance of cuBLAS SGEMM and our optimized SGEMM.
When matrix size is $12288\times12288$, the optimized SGEMM achieves $3104$ GFlop/s with $88\%$ efficiency, while cuBLAS gets $2509$ GFlop/s with $71\%$ efficiency. 
Our SGEMM achieves $17\%$ performance improvement over cuBLAS.

The overall trend Figure~\ref{fig:sgemm_tn} is that SGEMM performance increases with matrix sizes. 
%\jled{the next sentence change to ``On the one hand, a larger matrix has a higher arithmetic intensity 9$AI$), which is the ratio of compulsory floating-point operations to the total DRAM memory traffic.
%The high arithmetic intensity makes good use of GPU computing resources to obtain good performance.''}
On the one hand, a large matrix has a high ratio of 
floating-point operations to the store operations of matrix $C$, which is more close to the hardware arithmetic intensity. 
On the other hand, a larger matrix has a better load balance on GPU by increasing the workload of the threading CUDA
cores.
%\jled{change to ``number of threading blocks''}. 
The number of threading blocks range in $4 \times 4, 8 \times 8, \dots, 64 \times 64$ from left to right in Figure~\ref{fig:sgemm_tn}.
% $[768/192,768/192]=[4,4]$ to $[12288/192, 12288/192]$ $=[64,64]$. 
Since Kepler has $13$ SMs in total, matrix $768\times 768$ suffers more from load imbalance because of only a few ($16$) blocks. 
This is why a significant performance growth from $768$ to $1536$ for SGEMM. 
With respect to performance improvement over cuBLAS, our optimizations benefits more on larger matrices. 
The higher arithmetic intensity of larger matrices makes their performance increasingly bounded by the GPU microarchitecture rather than memory. 
Therefore, our microarchitecture-level optimization plays an important role on tuning 
performance.

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.6]{sgemm_tn}
\caption{Performance comparison of CUBLAS and the optimized SGEMM }
\label{fig:sgemm_tn}
\end{center}
\end{figure}

\subsection{Performance Analysis}

\subsubsection{Register Blocking Size Influence}
Table~\ref{tab:dm} summarized computation and data movement volume of blocking SGEMM algorithm.
The volume of data moving from shared memory to global memory is $rx\times bk+ ry\times bk$, and computation volume is $rx\times ry\times bk$. 
The shared memory arithmetic intensity ($sAI$) is defined as the ratio of floating-point operations to the shared memory traffic, which is 
\begin{equation}
sAI = \frac {rx\times 
ry\times bk} {rx\times bk+ ry\times bk} = \frac{1}{\frac{1}{rx} + \frac{1}{ry}}.
\end{equation}
This function implies that larger register blocks get the higher shared memory arithmetic intensity.
The optimal solution should be in the case of $rx=ry$. %\jled{what about C is not square matrix?}. 
For global memory, we have a similar conclusion.%\jled{Add another equation for $AI$}

However, register blocking size is limited by number of registers per thread. 
%the maximum number of threads in one block.
In order to hide shared memory latency, double-buffered software pipelining is an efficient way. 
Each thread needs $rx\times ry$ registers to store the result of a sub-matrix of $C$, $rx$ and $ry$ registers to store a block-column of $A$ and a block-row of $B$ in the same loop. 
For double-buffering, extra $rx$ and $ry$ registers are used to prefetch next block-column of $A$ and block-row of $B$ from shared memory. 
Since the total number of registers must be less than the maximal number of registers per thread ($256$ on Kepler), we have
\begin{equation}
    rx\times ry + rx\times 2 + ry\times 2 < 256.
\label{f_register}
\end{equation}
Because data load must be aligned in $128$-bit using 
{\tt LDG.128}, the block size could be $4\times 4$, $8\times 8$ or $12\times 12$. 
Since $4\times 4$ leads to low data reuse in register files, Figure~\ref{fig:block} plots $8\times8$ and $12\times12$ cases.
We choose $12\times12$ over $8\times8$ because
$12\times12$ blocking has higher $sAI$ and instruction level parallelism. 
With respect to 
instruction scheduling optimization as Table~\ref{tab:position}, it has more slots to insert scheduling instructions,
making the {\tt LDS} overhead being more easily amortized. 
Thus, $12*12+4*12=192$ registers are used by {\tt LD} and {\tt FFMA} instructions, and totally $236$ registers with
other address indices.%\jled{what other?}.
The number of registers per SM restricts us to launch up to $256$ threads. 
In our implementation, we have $256$ threads per block. 
Each thread block computes a $192\times 192$ sub-matrix of $C$ by multiplying $A_{192,4}$ and $B_{4, 192}$, where $4$ is the unrolling factor.

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.6]{block}
    \caption{Evaluation of different blocking sizes.} %\jled{could add $4\times4$ case.}}
\label{fig:block}
\end{center}
\end{figure}

Only one thread block per SM is active due to register limitation, thus the thread occupancy is $256/1024=12.5\%$.
With our high instruction level parallelism, the thread parallelism becomes low.
However, our SGEMM's high performance confirms that instruction level parallelism plays an more important role on GPU.
Similar conclusion is mentioned by Volkov in~\cite{volkov2010better}.

\subsubsection{Profiling Microarchitectural Optimization}

In order to examine performance gain of different optimization strategies, we construct several intermediate 
implementations by incrementally applying our microarchitectural optimizations.
\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.65]{tn_prof}
    \caption{Evaluation of the incremental optimizations.}
\label{fig:th_prof}
\end{center}
\end{figure}

{\it Baseline:}~~The baseline includes conventional optimizations including register blocking, global
memory double buffering, shared memory double buffering and unrolling, without assembly level optimization.
For example, the baseline uses default $32-bit$ {\tt LD} rather than $128-bit$ {\tt LDG} instruction to load data from global memory.
Registers is allocated orderly first for $C$, from $0$ to $143$, then for $A$ and $B$. 
In this case, {\tt FFMA}s have $368/(144*4)=63.89\%$ 2-way bank conflicts and $64/(144*4)=11.11\%$ 3-way bank conflicts. 
Besides, the baseline cannot apply dual issue optimization either.

{\it +Reg:}~~The register allocation pattern described in section~\ref{sec:register} is applied to eliminate register bank conflict. 
No optimization on instruction scheduling for this version.

{\it +LD128:}~~Use wider global load instruction {\tt LD128} with L2-cached.
Though Kepler has a L1 data cache, but it is designed for local rather than global memory access~\cite{gk110}.
% So {\tt LDx} will not be L1-cached, it can be L2-cached.

{\it +LDG128:}~~Use the texture cached {\tt LDG} which is faster than L2-cached {\tt LD}. 
When {\tt LDG} is used, {\tt TEXDEPBAR} is required before the data access due to weak consistence of texture cache~\cite{lukyanov2014efficient}.

{\it +Dual:}~~Use dual issue control, which is fully enabled by utilizing the pattern described in section~\ref{sec:assembler}.
%Single issue is controlled by setting control code to $0x40$. %\jled{different from section~\ref{sec:benchmark}. The left sentence is useless.}. 
For dual issued code, {\tt NOP} may be inserted for instruction alignment.

Figure~\ref{fig:th_prof} illustrates performance gains of each optimization method.
As long as the number of instructions is changed, rescheduling instruction order is needed to achieve good performance.
Compared to the baseline implementation, SGEMM gain up to $2.6\times$ speedup by applying all the optimization.
Register bank conflict eliminating improves around $10\%$ performance. 
Wider load instruction ({\tt LD128} improves $27\%-35\%$, texture cached
load instruction {\tt LDG128} improves $5\%-12\%$.
Dual issue improves the most, $84\%-106\%$.

\subsubsection{Upper Bound Analysis}

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.35]{roofline}
    \caption{Global memory roofline model using log-log scale. ``GM Bandwidth'' means global memory's theoretical bandwidth. Horizontal lines correspond to our incremental optimizations.}
\label{fig:roofline_global}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.35]{roofline_sm}
    \caption{Shared memory roofline model using log-log scale. ``SM Bandwidth'' means shared memory's theoretical bandwidth. Horizontal lines correspond to our incremental optimizations.}
\label{fig:roofline_shared}
\end{center}
\end{figure}


We estimate the upper bound factors: {\tt LDS}, {\tt LDG} and {\tt FFMA}. They correspond to three kinds of resources, 
shared
memory, global memory and computation power. In register blocking loop, each thread compute $bm*bn*bk$, read $bm*bk$
and $bn*bk$ words. The upper bound of global memory bandwidth can be modeled as:
\begin{displaymath}
    \frac{2*bm*bn*bk}{4*(bm*bk + bn*bk)} = \frac{Gflop/s}{bandwidth}
\end{displaymath}
According to parameters in our SGEMM implementation, $bm=bn=192$, $bk=4$, $Gflop/s=3520$, so $73$ GB/s is the minimal
requirement for global memory bandwidth in order to achieve peak $3520$ Gflops.
For shared memory, inside each loop, $(rx*bk + ry * bk)*tx*ty$ words will be read from shared memory, in which $tx$,
$ty$ is block dimension, $rx$, $ry$ is register blocking size. The computation is $bm*bn*bk$. Based on computation
shared memory ration,
\begin{displaymath}
    \frac{2*bm*bk*bn}{4*tx*ty*(rx*bk + ry *bk)}  = \frac{Gflop/s}{bandwidth}
\end{displaymath}

On Kepler GPU the minimum bandwidth requirement is $1173$GB/s, and for each SM of Kepler, bandwidth requirement is
$1173/13=90$ GB/s. The hardware can provide $200$GB/s global memory bandwidth and $2349$GB/s shared memory bandwidth in
theory, which is higher than requirement, and hence neither bandwidth of shared width nor global memory will be bottleneck.

SGEMM has different computation to memory ratio in terms of  global memory and shared memory, so we draw two roofline models. 
The slope of slash lines in Figure~\ref{fig:roofline_global} is bandwidth of global memory. The x-axis is computation to global
memory access ratio of an application. For SGEMM, by $12\times12$, the ratio is $48$, by $8\times 8$ blocking, the ratio
is $32$. The horizontal black lines corresponding to our {\tt FFMA} throughput optimization which including elimanating
register banks, choosing proper load width. Our SGEMM currently achieves at the red line. This figure demonstrates that
by $12\times12$ blocking, SGEMM is not global memory bounded.
The slope of slash lines in Figure~\ref{fig:roofline_shared} is bandwidth of shared memory. The x-axis is computation to
shared memory access ratio of an application. For SGEMM, by $12\times12$, the ratio is $3$, by $8\times 8$ blocking, the ratio is $2$. 
This figure shows by our optimization,  SGEMM will not be bounded by shared memory. However, if we use {\tt LDS.128} instead of
{\tt LDS.64}, even $12\times 12$ blocking, SGEMM will be bounded by shared memory.

The loss to peak performance can be explained as the following reasons. As we have shown in 
Section~\ref{sec:assembler}, {\tt FFMA} throughput can achieve $97.67\%$. The loss is about $2.33\%$, which may comes 
from overhead of warp scheduler in {\tt FFMA} dual issue mode. The double-buffering algorithm can amortize the latency 
of {\tt LDS}.
With $12x12$ register blocking and $4$ times unrolling, there will be $144*4=576$ {\tt FFMA} instructions in the loop.
With our designed {\tt FFMA} dual issue pattern, every $6$ {\tt FFMA} needs $4$ clock cycles in the pipeline.
It needs $4*144*4/6=384$ clock cycles for each thread,  two $128$ bits {\tt LDG} instruction are needed.
We observe each {\tt LDG} has $10$ clock penalty, the total {\tt LDG} will cause $2*10/384 = 5.2\%$ loss. Other penalty 
comes from synchronization and writing $C$ matrix in the block.
