\begin{abstract}
In this paper, we present a methodology to demystify GPU's microarchitecture level features and demonstrate how to use
them to tune SGEMM. The methodology relies on a reverse engineering approach to crack the GPU instruction encoding, and
a profound microbenchmarking at assembly level to correlate architecture features with
performance factors, such as dual issue impact on float arithmetic throughput, memory load width on bandwidth, register 
bank distribution on performance etc. 
Based on these disclosed information, we implemented the fastest SGEMM on Kepler GPU. 
The performance boost is achieved on the basis of tuning {\tt FFMA} throughput as high as 
hardware peak by activating dual issue and eliminating bank conflicts, then add other non-FFMA instruction with little
penalty by choosing proper width of global load and shared memory load instructions, and instruction scheduling. 
The optimized SGEMM achieves $3104$ Gflop/s and its efficiency is $88\%$, which is 17\% higher than cuBLAS's SGEMM on Kepler GPU.
% Then, we use a roofline model to analyze the upper bound of SGEMM.
%We build two roofline models for shared and global memory separately, which reveal that even for compute-intensive SGEMM kernel, without appropriately optimizations or good resource usage, its performance could also be memory-bound.\jled{Please check this sentence! Or remove it.}
% $17\%$ higher than Cublas. 
\end{abstract}

