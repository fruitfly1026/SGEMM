\section{Conclusion}
\label{sec:conclusion}
We have presented a methodology to demystify GPU?s microarchitecture level optimizations and demonstrated its application to tune SGEMM. The methodology relies on a reverse engineering approach to crack the instruction encoding of GPU architecture, and a profound microbenchmarking at assembly level to correlate architecture features with performance factors, such as dual issue impact on float arithmetic throughput, memory load width on bandwidth, register bank distribution on performance etc. These parameters are worthwhile for both hardware and software researcher to understand how GPU architecture is designed and how to adapt program to GPU hardware. As far as we know, it is the first time to provide a detailed description of how we cracked the instruction encoding by presenting our decoding solver. This solver is not limited to Kepler GPU, it can be used to crack the future GPU encoding automatically. 

Based on these disclosed information, we implemented the fastest SGEMM on Kepler GPU. The optimized SGEMM is $3104$ Gflop/s and efficiency is $88\%$, CUBLAS's SGEMM achieves $2509$ Gflp/s ($71\%$ efficiency). Our optimized one is $17\%$ higher than Cublas. The performance boost is achieved on the basis of tuning {\tt FFMA} throughput as high as hardware peak, then add other non-FFMA instruction with little penalty. These optimizations include register bank conflict eliminating, {\tt FFMA} dual issue scheduling, choosing proper width of global load and shared memory load instructions and so on. Our work opens a door to optimize NVIDIA GPU code at native machine level.

