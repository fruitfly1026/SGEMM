\section{Related Work}
\label{sec:related}
To our knowledge, this paper provides the first comprehensive study of demystifying NVIDIA GPU microarchitecture which 
is correlated with performance tuning in SGEMM. This section briefly discusses related work in assembler, 
microbenchmarking and SGEMM optimization.

{\em {\bf ISA Encoding and GPU Assembler}}:The lack of assembler for public use motivates a series of work on developing toolchains to facilitate tuning codes in 
assembly level. For the early architecture G80, Decuda~\cite{decuda} demonstrated the feasibility to operate the 
limited number of assembly instructions. After that, for almost each new generation of CUDA architecture, there are several 
efforts on developing assembly toolchains. Both Hou's Asfermi~\cite{asfermi} and Bernstein's 
cudaasm-qhasm~\cite{bernstein2012usable} are assemblers for Fermi architecture. Gray built MaxAs~\cite{maxas} assembler 
for Maxwell architecture by reverse engineering the encoding of Maxwell GPU. Our work provides a complete assembler for 
Kepler architecture. A remarkable advantage of our assembly toolchain is the compatibility with CUDA's {\tt cuobjdump}. 
As a comparison, although Envytools~\cite{envytools} supports translation of PTX instruction to $64$-bit binaries 
for serval GPU architectures, it is not able to generate a compatible {\tt cubin} format which can be directly used by 
the CUDA driver APIs. Besides, no prior work presents the detailed instruction decoding algorithms process as ours.

%We share the same idea of performance microbenchmarking with other works. 
{\em {\bf Benchmarking}}: Wong et.al.~\cite{wong} performed a 
comprehensive benchmarking work on GT200 and provided pipeline latency data and
memory features. Mei~\cite{mei} benchmarked memory hierarchy including cache, shared memory on Fermi, Kepler and Maxwell GPU
However, neither of them benchmarked 
vectorized load instructions like {\tt LD} and {\tt LDS}. 
%Due to lack of considering vectorized load instructions and 
%too less instructions inside the loop, the results is not so accurate.
No vectorized load instructions and too few instructions inside the loop lead to results with unsatisfying accuracy.
Neither of them considered dual issue mode of 
arithmetic instructions. We leverage the complete assembler to crack control codes which reveal more 
microarchitecture details for tuning application performance.

{\em {\bf Matrix Multiplication Tuning}}: With respect to GEMM optimization in microarchitectural level, some work inspires our implementation 
on specific GPUs. For example, we adopt the proved effective optimization techniques like shared memory/register 
blocking and double-buffering~\cite{volkov}~\cite{tan}. Further, Tan et.al.~\cite{tan} implemented fast DGEMM by using 
assembly level optimization, such as software pipelining, vector memory operations, and instruction scheduling. 
Lai~\cite{lai} presented performance analysis and optimization work of SGEMM on both Fermi and GTX680 GPUs. However, 
Lai didn't consider dual issue mode by setting control code, which can boost performance significantly. Scott 
Gray~\cite{nervana_sgemm_wiki} presented optimization of SGEMM in assembly on Maxwell GPU. Since Maxwell does not 
support {\tt FFMA} dual issue, the optimization is much easier than
Kepler. In contrast, we present a complete case of applying microarchitectural features by combining instruction 
scheduling, register allocation, and memory access paths. 
