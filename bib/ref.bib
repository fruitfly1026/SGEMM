@inproceedings{tan,
  title={Fast implementation of DGEMM on Fermi GPU},
  author={Tan, Guangming and Li, Linchuan and Triechle, Sean and Phillips, Everett and Bao, Yungang and Sun, Ninghui},
  booktitle={Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={35},
  year={2011},
  organization={ACM}
}
@inproceedings{lai,
  title={Performance upper bound analysis and optimization of sgemm on fermi and kepler gpus},
  author={Lai, Junjie and Seznec, Andr{\'e}},
  booktitle={Code Generation and Optimization (CGO), 2013 IEEE/ACM International Symposium on},
  pages={1--10},
  year={2013},
  organization={IEEE}
}
@inproceedings{volkov,
  title={Benchmarking GPUs to tune dense linear algebra},
  author={Volkov, Vasily and Demmel, James W},
  booktitle={High Performance Computing, Networking, Storage and Analysis, 2008. SC 2008. International Conference for},
  pages={1--11},
  year={2008},
  organization={IEEE}
}
@inproceedings{wong,
  title={Demystifying GPU microarchitecture through microbenchmarking},
  author={Wong, Henry and Papadopoulou, Misel-Myrto and Sadooghi-Alvandi, Maryam and Moshovos, Andreas},
  booktitle={Performance Analysis of Systems \& Software (ISPASS), 2010 IEEE International Symposium on},
  pages={235--246},
  year={2010},
  organization={IEEE}
}
@inproceedings{yu2015performance,
  title={Performance optimization for the k-nearest neighbors kernel on x86 architectures},
  author={Yu, Chenhan D and Huang, Jianyu and Austin, Woody and Xiao, Bo and Biros, George},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={7},
  year={2015},
  organization={ACM}
}

@misc{top500_2015_nov,
        author = {Hans Meuer and Erich Strohmaier and Jack Dongarra and Horst Simon}, 
        title = {Top500},
        howpublished = {\url{http://www.top500.org/system/177975}}
}
@misc{nervana_sgemm_wiki,
    author = {Scott Gray},
    title = {NervanaGPU},
    howpublished = {\url{https://github.com/NervanaSystems/maxas/wiki/SGEMM}}
}
@misc{maxas,
    author = {Scott Gray},
    title = {MaxAs},
    howpublished = {\url{https://github.com/NervanaSystems/maxas}}
}
@misc{decuda,
    author = {Wladimir J. van der Laan },
    title = {Decuda},
    howpublished = {\url{https://github.com/laanwj/decuda}}
}
@misc {envytools,
    title={Envytools},
    howpublished = {\url{https://github.com/envytools/envytools}}
}
@article{bernstein2012usable,
  title={Usable assembly language for GPUs: a success story.},
  author={Bernstein, Daniel J and Chen, Hsieh-Chung and Cheng, Chen-Mou and Lange, Tanja and Niederhagen, Ruben and Schwabe, Peter and Yang, Bo-Yin},
  journal={IACR Cryptology ePrint Archive},
  volume={2012},
  pages={137},
  year={2012}
}

@misc{asfermi,
    author = {Yunqing Hou},
    title = {AsFermi},
    howpublished = {\url{https://code.google.com/archive/p/asfermi/wikis}}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}
@misc{ptx2015isa,
  title = {PARALLEL THREAD EXECUTION ISA v4.3},
  howpublished  = {\url{http://docs.nvidia.com/cuda/parallel-thread-execution/#axzz42f7ftJVy}},
  author = {NVIDIA},
  year={September 2015}
}

@article{cuda2015programming,
  title={CUDA C programming guide version v7.5},
  author={NVidia},
  year={September 2015}
}

@article{cubin2015util,
  title={CUDA BINARY UTILITIES},
  author={NVidia},
  year={September 2015}
}

@article{cuda2015best,
  title={CUDA C programming best practices guide v7.5},
  howpublished  = {\url{http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/#axzz42f7ftJVy}},
  author={NVidia},
  year={September 2015}
}
@article{nvcc,
  title={CUDA COMPILER DRIVER NVCC v7.5},
  howpublished  = {\url{http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/#axzz42f7ftJVy}},
  author={NVidia},
  year={September 2015}
}
@article{xianyi2012openblas,
  title={OpenBLAS},
  author={Xianyi, Zhang and Qian, Wang and Chothia, Zaheer},
  journal={URL: http://xianyi. github. io/OpenBLAS},
  year={2012}
}
@misc{gk110,
    title = {NVIDIAs Next Generation CUDA TM Compute Architecture:Kepler TM GK110 The Fastest, Most
        Efficient HPC Architecture Ever Built},
    author={Nvidia},
    howpublished={White Paper},
    year={2012}
}
@misc{fermi,
  title={Next Generation CUDA TM Compute Architecture: Fermi},
  howpublished={White Paper},
  author={NVIDIA},
  year={2009}
}
@techreport{magma,
  title={An improved MAGMA GEMM for Fermi GPUs, University of Tennessee Computer Science Technical Report},
  author={Nath, R and Tomov, S and Dongarra, J},
  year={2010},
  institution={UTCS-10-655, July}
}
@article{fog,
  title={Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs},
  author={Fog, Agner},
  journal={Denmark (Lyngby): Technical University of Denmark},
  year={2012}
}
@misc{collector,
  title={Methods and apparatus for source operand collector caching},
  author={Choquette, Jack Hilaire and Gautho, Manuel Olivier and Lindholm, John Erik},
  year={2014},
  month=jan # "~28",
  publisher={Google Patents},
  note={US Patent 8,639,882}
}
@incollection{mei,
  title={Benchmarking the memory hierarchy of modern GPUs},
  author={Mei, Xinxin and Zhao, Kaiyong and Liu, Chengjian and Chu, Xiaowen},
  booktitle={Network and Parallel Computing},
  pages={144--156},
  year={2014},
  publisher={Springer}
}
@incollection{sgd,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}
@article{blas,
  title={A set of level 3 basic linear algebra subprograms},
  author={Dongarra, Jack J and Du Croz, Jeremy and Hammarling, Sven and Duff, Iain S},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={16},
  number={1},
  pages={1--17},
  year={1990},
  publisher={ACM}
}
@inproceedings{lapack,
  title={LAPACK: A portable linear algebra library for high-performance computers},
  author={Anderson, Edward and Bai, Zhaojun and Dongarra, Jack and Greenbaum, Anne and McKenney, Alan and Du Croz, Jeremy and Hammerling, Sven and Demmel, James and Bischof, C and Sorensen, Danny},
  booktitle={Proceedings of the 1990 ACM/IEEE conference on Supercomputing},
  pages={2--11},
  year={1990},
  organization={IEEE Computer Society Press}
}
@article{dis,
    title={OpenNVISA â€” NVIDIA GPU native assembler for the masses},
    author={Dmitry, Mikushin and Nikolay, Likhogrud and Eddy, Z. Zhang},
    publisher={}
}
@techreport{chien,
  title={Hand Tuned SGEMM on GT200 GPU},
  author={Chien, Lung-Sheng},
  year={2010},
  institution={Tech. rep., Department of Mathematics, Tsing Hua University, Taiwan}
}
@article{chetlur2014cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}
@inproceedings{hsieh2001reverse,
  title={Reverse-Engineering Instruction Encodings.},
  author={Hsieh, Wilson C and Engler, Dawson R and Back, Godmar},
  booktitle={USENIX Annual Technical Conference, General Track},
  pages={133--145},
  year={2001}
}
@misc{intel2007intel,
  title={Intel math kernel library},
  author={Intel, MKL},
  year={2007},
  publisher={ed}
}

@misc{amd2014,
title={AMD Core Math Library (ACML)},
  author={AMD, ACML},
  year={2014},
  publisher={White Paper}
}
@article{nvidia2008cublas,
  title={Cublas library},
  author={Nvidia, CUDA},
  journal={NVIDIA Corporation, Santa Clara, California},
  year={2015}
}

@misc{nervana_sgemm_wiki,
    author = {Scott Gray},
    title = {NervanaGPU},
    howpublished = {\url{https://github.com/clMathLibraries}}
}

@misc{gtx980,
  title={NVIDIA GeForce GTX 980},
  howpublished={White Paper},
  author={NVIDIA},
  year={2014}
}

@misc{maxwell_tune,
  title={TUNING CUDA APPLICATIONS FOR MAXWELL},
  howpublished={White Paper},
  author={NVIDIA},
  year={2014}
}
@misc{kepler_tune,
  title={TUNING CUDA APPLICATIONS FOR Kepler},
  howpublished={White Paper},
  author={NVIDIA},
  year={2014}
}
